{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from feature_eng import *\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and check data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Broome county data \n",
    "\n",
    "path = os.environ.get(\"path\")\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SBOEID', 'RZIP5', 'ED', 'LD', 'ENROLLMENT', 'REGDATE', 'STATUS',\n",
       "       'voterhistory', 'DOB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SBOEID', 'RZIP5', 'ED', 'LD', 'ENROLLMENT', 'REGDATE', 'STATUS',\n",
       "       'voterhistory', 'DOB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.rename(columns = {'VoterHistory':'voterhistory'})\n",
    "\n",
    "data.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_on_features(df_with_features, feature_cols, target_col='target', test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Compare multiple models with fixed probability handling\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                                f1_score, roc_auc_score, confusion_matrix, \n",
    "                                classification_report)\n",
    "    import time\n",
    "    \n",
    "    print(\"Preparing data for model comparison...\")\n",
    "    \n",
    "    # Ensure we have the features\n",
    "    X = df_with_features[feature_cols].fillna(0)\n",
    "    y = df_with_features[target_col]\n",
    "    \n",
    "    # Check class distribution\n",
    "    print(f\"Target distribution: {y.value_counts()}\")\n",
    "    print(f\"Target ratio: {y.mean():.3f}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining set: {len(X_train)} samples\")\n",
    "    print(f\"Test set: {len(X_test)} samples\")\n",
    "    \n",
    "    # Define models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=random_state, max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            n_estimators=100, \n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        'LightGBM': LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            num_leaves=31,\n",
    "            random_state=random_state,\n",
    "            verbose=-1\n",
    "        ),\n",
    "        'XGBoost': XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            random_state=random_state,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training {name}...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Handle probability predictions safely\n",
    "            y_pred_proba = None\n",
    "            auc_score = None\n",
    "            \n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                try:\n",
    "                    proba_result = model.predict_proba(X_test)\n",
    "                    \n",
    "                    # Check the shape of probability output\n",
    "                    if proba_result.ndim == 2 and proba_result.shape[1] == 2:\n",
    "                        # Binary classification with both classes\n",
    "                        y_pred_proba = proba_result[:, 1]\n",
    "                    elif proba_result.ndim == 2 and proba_result.shape[1] == 1:\n",
    "                        # Only one class probability returned\n",
    "                        y_pred_proba = proba_result[:, 0]\n",
    "                    elif proba_result.ndim == 1:\n",
    "                        # Single array of probabilities\n",
    "                        y_pred_proba = proba_result\n",
    "                    else:\n",
    "                        print(f\"Unexpected probability shape: {proba_result.shape}\")\n",
    "                        y_pred_proba = None\n",
    "                        \n",
    "                    if y_pred_proba is not None:\n",
    "                        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error getting probabilities: {e}\")\n",
    "                    y_pred_proba = None\n",
    "                    auc_score = None\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "            \n",
    "            # Confusion matrix\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            \n",
    "            # Training time\n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Store results\n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'auc': auc_score,\n",
    "                'confusion_matrix': cm,\n",
    "                'true_negatives': tn,\n",
    "                'false_positives': fp,\n",
    "                'false_negatives': fn,\n",
    "                'true_positives': tp,\n",
    "                'training_time': training_time,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba\n",
    "            }\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Precision: {precision:.4f}\")\n",
    "            print(f\"Recall: {recall:.4f}\")\n",
    "            print(f\"F1 Score: {f1:.4f}\")\n",
    "            if auc_score is not None:\n",
    "                print(f\"AUC: {auc_score:.4f}\")\n",
    "            else:\n",
    "                print(\"AUC: Not available\")\n",
    "            print(f\"Training time: {training_time:.2f} seconds\")\n",
    "            \n",
    "            print(f\"\\nConfusion Matrix:\")\n",
    "            print(f\"TN: {tn}, FP: {fp}\")\n",
    "            print(f\"FN: {fn}, TP: {tp}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {name}: {e}\")\n",
    "            results[name] = {\n",
    "                'error': str(e),\n",
    "                'accuracy': 0,\n",
    "                'auc': 0\n",
    "            }\n",
    "    \n",
    "    # Create summary comparison\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Model Comparison Summary:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    summary_data = []\n",
    "    for name, result in results.items():\n",
    "        if 'error' not in result:\n",
    "            summary_data.append({\n",
    "                'Model': name,\n",
    "                'Accuracy': f\"{result['accuracy']:.4f}\",\n",
    "                'AUC': f\"{result['auc']:.4f}\" if result['auc'] is not None else \"N/A\",\n",
    "                'Precision': f\"{result['precision']:.4f}\",\n",
    "                'Recall': f\"{result['recall']:.4f}\",\n",
    "                'F1': f\"{result['f1']:.4f}\",\n",
    "                'Time (s)': f\"{result['training_time']:.2f}\"\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Find best model by AUC (if available) or accuracy\n",
    "    valid_results = {k: v for k, v in results.items() if 'error' not in v}\n",
    "    \n",
    "    # Sort by AUC if available, otherwise by accuracy\n",
    "    if any(r['auc'] is not None for r in valid_results.values()):\n",
    "        best_model = max(valid_results.items(), \n",
    "                        key=lambda x: x[1]['auc'] if x[1]['auc'] is not None else 0)\n",
    "        metric_used = 'AUC'\n",
    "    else:\n",
    "        best_model = max(valid_results.items(), \n",
    "                        key=lambda x: x[1]['accuracy'])\n",
    "        metric_used = 'Accuracy'\n",
    "    \n",
    "    print(f\"\\nBest model by {metric_used}: {best_model[0]}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Also create a function to safely get prediction probabilities\n",
    "def safe_predict_proba(model, X):\n",
    "    \"\"\"\n",
    "    Safely get prediction probabilities, handling different model outputs\n",
    "    \"\"\"\n",
    "    if not hasattr(model, \"predict_proba\"):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        proba = model.predict_proba(X)\n",
    "        \n",
    "        # Handle different output shapes\n",
    "        if proba.ndim == 2 and proba.shape[1] == 2:\n",
    "            # Standard binary classification\n",
    "            return proba[:, 1]\n",
    "        elif proba.ndim == 2 and proba.shape[1] == 1:\n",
    "            # Single column output\n",
    "            return proba[:, 0]\n",
    "        elif proba.ndim == 1:\n",
    "            # Already 1D\n",
    "            return proba\n",
    "        else:\n",
    "            print(f\"Unexpected probability shape: {proba.shape}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting probabilities: {e}\")\n",
    "        return None\n",
    "\n",
    "def visualize_model_comparison(results):\n",
    "    \"\"\"\n",
    "    Visualize model comparison results\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary with model results\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Create a DataFrame with the results\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc', 'cv_mean']\n",
    "    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'CV AUC']\n",
    "    \n",
    "    data = []\n",
    "    for model_name, metrics_dict in results.items():\n",
    "        row = {'Model': model_name}\n",
    "        for metric in metrics:\n",
    "            if metric in metrics_dict and metrics_dict[metric] is not None:\n",
    "                row[metric] = metrics_dict[metric]\n",
    "            else:\n",
    "                row[metric] = None\n",
    "        data.append(row)\n",
    "    \n",
    "    df_metrics = pd.DataFrame(data)\n",
    "    \n",
    "    # Plot the metrics for each model\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    df_plot = df_metrics.melt(\n",
    "        id_vars=['Model'], \n",
    "        value_vars=[m for m in metrics if m != 'cv_mean'],\n",
    "        var_name='Metric', value_name='Value'\n",
    "    )\n",
    "    \n",
    "    # Map metric keys to friendly names\n",
    "    metric_map = dict(zip(metrics, metric_names))\n",
    "    df_plot['Metric'] = df_plot['Metric'].map(lambda x: metric_map.get(x, x))\n",
    "    \n",
    "    # Create the plot\n",
    "    sns.barplot(x='Model', y='Value', hue='Metric', data=df_plot)\n",
    "    plt.title('Model Comparison Across Metrics')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot cross-validation results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cv_data = []\n",
    "    for model_name, metrics_dict in results.items():\n",
    "        if 'cv_scores' in metrics_dict:\n",
    "            for score in metrics_dict['cv_scores']:\n",
    "                cv_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'CV AUC': score\n",
    "                })\n",
    "    \n",
    "    df_cv = pd.DataFrame(cv_data)\n",
    "    sns.boxplot(x='Model', y='CV AUC', data=df_cv)\n",
    "    plt.title('Cross-validation AUC Scores')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot confusion matrices\n",
    "    nrows = (len(results) + 2) // 3  # Calculate rows needed\n",
    "    fig, axes = plt.subplots(nrows, 3, figsize=(15, 4 * nrows))\n",
    "    axes = axes.flatten() if nrows > 1 else [axes]\n",
    "    \n",
    "    for i, (model_name, metrics_dict) in enumerate(results.items()):\n",
    "        if i < len(axes) and 'confusion_matrix' in metrics_dict:\n",
    "            ax = axes[i]\n",
    "            cm = metrics_dict['confusion_matrix']\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "            ax.set_title(f'{model_name} Confusion Matrix')\n",
    "            ax.set_xlabel('Predicted')\n",
    "            ax.set_ylabel('Actual')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_feature_importance(model, feature_names, model_name='Model'):\n",
    "    \"\"\"\n",
    "    Visualize feature importance for a model\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model with feature_importances_ attribute\n",
    "        feature_names: List of feature names\n",
    "        model_name: Name of the model\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # Create a DataFrame for easier visualization\n",
    "    df_importances = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    df_importances = df_importances.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=df_importances)\n",
    "    plt.title(f'{model_name} Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting clean features from 146429 voter records\n",
      "Parsing voter histories...\n",
      "Kept 120751 voters with valid parsed histories\n",
      "Deriving all election dates from voter histories...\n",
      "Derived 59 election dates\n",
      "Mayoral election years: [2021, 2017, 2013, 2009, 2005, 2001]\n",
      "Local election years: [2003, 2007, 2011, 2015, 2019, 2023, 2027]\n",
      "Extracting features...\n",
      "Calculating first election information...\n",
      "Calculating normalized participation rates...\n",
      "Calculating mayoral and local participation rates...\n",
      "Setting target variable...\n",
      "Calculating voting trends...\n",
      "Feature extraction complete\n",
      "Extracting behavior change features...\n"
     ]
    }
   ],
   "source": [
    "#mayoral elections to train on\n",
    "mayoral_election_dates = [\n",
    "            '20211102',\n",
    "            '20171107', \n",
    "            '20131105',\n",
    "            '20091103',\n",
    "            '20051108',\n",
    "            '20011106'\n",
    "        ]\n",
    "\n",
    "train_df, feature_names = extract_clean_features_enhanced(data, parse_voter_history, mayoral_election_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SBOEID', 'RZIP5', 'ED', 'LD', 'ENROLLMENT', 'REGDATE', 'STATUS',\n",
       "       'voterhistory', 'DOB', 'parsed_history', 'has_voting_history',\n",
       "       'total_votes', 'voted_general', 'voted_primary', 'voted_local',\n",
       "       'is_consistent_voter', 'first_election_year', 'years_registered',\n",
       "       'elections_since_first', 'participation_rate',\n",
       "       'mayoral_participation_rate', 'local_participation_rate',\n",
       "       'voted_last_mayoral', 'voting_trend', 'preferred_method',\n",
       "       'prefers_early_voting', 'prefers_absentee', 'recent_method_change',\n",
       "       'recency_score', 'early_to_middle_change', 'middle_to_recent_change',\n",
       "       'participation_acceleration', 'avg_gap', 'gap_variability',\n",
       "       'longest_participation_streak', 'recent_pattern_change',\n",
       "       'participation_expansion', 'diversification_score',\n",
       "       'has_behavior_change', 'years_since_last_change', 'change_direction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for model comparison...\n",
      "Target distribution: 0    86384\n",
      "1    34367\n",
      "Name: voted_last_mayoral, dtype: int64\n",
      "Target ratio: 0.285\n",
      "\n",
      "Training set: 84525 samples\n",
      "Test set: 36226 samples\n",
      "\n",
      "==================================================\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9502\n",
      "Precision: 0.9080\n",
      "Recall: 0.9181\n",
      "F1 Score: 0.9130\n",
      "AUC: 0.9889\n",
      "Training time: 7.40 seconds\n",
      "\n",
      "Confusion Matrix:\n",
      "TN: 24957, FP: 959\n",
      "FN: 844, TP: 9466\n",
      "\n",
      "==================================================\n",
      "Training Random Forest...\n",
      "Accuracy: 0.9935\n",
      "Precision: 0.9886\n",
      "Recall: 0.9885\n",
      "F1 Score: 0.9885\n",
      "AUC: 0.9994\n",
      "Training time: 1.34 seconds\n",
      "\n",
      "Confusion Matrix:\n",
      "TN: 25798, FP: 118\n",
      "FN: 119, TP: 10191\n",
      "\n",
      "==================================================\n",
      "Training Gradient Boosting...\n",
      "Accuracy: 0.9867\n",
      "Precision: 0.9775\n",
      "Recall: 0.9758\n",
      "F1 Score: 0.9766\n",
      "AUC: 0.9983\n",
      "Training time: 10.76 seconds\n",
      "\n",
      "Confusion Matrix:\n",
      "TN: 25684, FP: 232\n",
      "FN: 250, TP: 10060\n",
      "\n",
      "==================================================\n",
      "Training LightGBM...\n",
      "Accuracy: 0.9947\n",
      "Precision: 0.9878\n",
      "Recall: 0.9938\n",
      "F1 Score: 0.9908\n",
      "AUC: 0.9996\n",
      "Training time: 0.67 seconds\n",
      "\n",
      "Confusion Matrix:\n",
      "TN: 25789, FP: 127\n",
      "FN: 64, TP: 10246\n",
      "\n",
      "==================================================\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/anaconda3/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:25:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9934\n",
      "Precision: 0.9870\n",
      "Recall: 0.9899\n",
      "F1 Score: 0.9885\n",
      "AUC: 0.9994\n",
      "Training time: 0.47 seconds\n",
      "\n",
      "Confusion Matrix:\n",
      "TN: 25782, FP: 134\n",
      "FN: 104, TP: 10206\n",
      "\n",
      "==================================================\n",
      "Model Comparison Summary:\n",
      "==================================================\n",
      "              Model Accuracy    AUC Precision Recall     F1 Time (s)\n",
      "Logistic Regression   0.9502 0.9889    0.9080 0.9181 0.9130     7.40\n",
      "      Random Forest   0.9935 0.9994    0.9886 0.9885 0.9885     1.34\n",
      "  Gradient Boosting   0.9867 0.9983    0.9775 0.9758 0.9766    10.76\n",
      "           LightGBM   0.9947 0.9996    0.9878 0.9938 0.9908     0.67\n",
      "            XGBoost   0.9934 0.9994    0.9870 0.9899 0.9885     0.47\n",
      "\n",
      "Best model by AUC: LightGBM\n"
     ]
    }
   ],
   "source": [
    "# Now compare different models\n",
    "model_results = compare_models_on_features(train_df, feature_names, 'voted_last_mayoral')\n",
    "\n",
    "# Get the best model\n",
    "best_model_name = max(model_results.items(), key=lambda x: x[1]['auc'] if x[1]['auc'] is not None else 0)[0]\n",
    "best_model = model_results[best_model_name]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'model': LogisticRegression(max_iter=1000, random_state=42),\n",
       "  'accuracy': 0.9563685636856368,\n",
       "  'precision': 0.9272211720226843,\n",
       "  'recall': 0.9211267605633803,\n",
       "  'f1': 0.9241639189825719,\n",
       "  'auc': 0.9928236083165661,\n",
       "  'confusion_matrix': array([[5096,  154],\n",
       "         [ 168, 1962]]),\n",
       "  'true_negatives': 5096,\n",
       "  'false_positives': 154,\n",
       "  'false_negatives': 168,\n",
       "  'true_positives': 1962,\n",
       "  'training_time': 2.7264599800109863,\n",
       "  'y_pred': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "  'y_pred_proba': array([0.01317703, 0.00214133, 0.36519367, ..., 0.18061206, 0.47216481,\n",
       "         0.0113504 ])},\n",
       " 'Random Forest': {'model': RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "  'accuracy': 0.9887533875338753,\n",
       "  'precision': 0.989010989010989,\n",
       "  'recall': 0.971830985915493,\n",
       "  'f1': 0.980345725787355,\n",
       "  'auc': 0.9988326849988822,\n",
       "  'confusion_matrix': array([[5227,   23],\n",
       "         [  60, 2070]]),\n",
       "  'true_negatives': 5227,\n",
       "  'false_positives': 23,\n",
       "  'false_negatives': 60,\n",
       "  'true_positives': 2070,\n",
       "  'training_time': 0.36078619956970215,\n",
       "  'y_pred': array([0, 0, 0, ..., 0, 1, 0]),\n",
       "  'y_pred_proba': array([0.  , 0.  , 0.06, ..., 0.12, 0.89, 0.  ])},\n",
       " 'Gradient Boosting': {'model': GradientBoostingClassifier(random_state=42),\n",
       "  'accuracy': 0.9888888888888889,\n",
       "  'precision': 0.9825636192271442,\n",
       "  'recall': 0.9788732394366197,\n",
       "  'f1': 0.9807149576669801,\n",
       "  'auc': 0.9991291750503019,\n",
       "  'confusion_matrix': array([[5213,   37],\n",
       "         [  45, 2085]]),\n",
       "  'true_negatives': 5213,\n",
       "  'false_positives': 37,\n",
       "  'false_negatives': 45,\n",
       "  'true_positives': 2085,\n",
       "  'training_time': 2.051537036895752,\n",
       "  'y_pred': array([0, 0, 0, ..., 0, 1, 0]),\n",
       "  'y_pred_proba': array([0.00119729, 0.00095752, 0.05238527, ..., 0.32760872, 0.92102851,\n",
       "         0.00142141])},\n",
       " 'LightGBM': {'model': LGBMClassifier(random_state=42, verbose=-1),\n",
       "  'accuracy': 0.9936314363143631,\n",
       "  'precision': 0.9896567936060179,\n",
       "  'recall': 0.9882629107981221,\n",
       "  'f1': 0.9889593610523844,\n",
       "  'auc': 0.9995694164989939,\n",
       "  'confusion_matrix': array([[5228,   22],\n",
       "         [  25, 2105]]),\n",
       "  'true_negatives': 5228,\n",
       "  'false_positives': 22,\n",
       "  'false_negatives': 25,\n",
       "  'true_positives': 2105,\n",
       "  'training_time': 0.2006371021270752,\n",
       "  'y_pred': array([0, 0, 0, ..., 0, 1, 0]),\n",
       "  'y_pred_proba': array([1.26918801e-05, 1.26918801e-05, 2.65336986e-03, ...,\n",
       "         5.49391523e-02, 9.97162466e-01, 1.58549330e-05])},\n",
       " 'XGBoost': {'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric='logloss',\n",
       "                feature_types=None, gamma=None, grow_policy=None,\n",
       "                importance_type=None, interaction_constraints=None,\n",
       "                learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "                max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "                n_jobs=None, num_parallel_tree=None, random_state=42, ...),\n",
       "  'accuracy': 0.9914634146341463,\n",
       "  'precision': 0.9895783988630981,\n",
       "  'recall': 0.9807511737089202,\n",
       "  'f1': 0.9851450129686394,\n",
       "  'auc': 0.9993361949474626,\n",
       "  'confusion_matrix': array([[5228,   22],\n",
       "         [  41, 2089]]),\n",
       "  'true_negatives': 5228,\n",
       "  'false_positives': 22,\n",
       "  'false_negatives': 41,\n",
       "  'true_positives': 2089,\n",
       "  'training_time': 0.2170400619506836,\n",
       "  'y_pred': array([0, 0, 0, ..., 0, 1, 0]),\n",
       "  'y_pred_proba': array([6.8959809e-05, 8.6227868e-05, 2.1740833e-02, ..., 2.2683464e-01,\n",
       "         9.8720932e-01, 1.1895051e-04], dtype=float32)},\n",
       " 'Neural Network': {'model': MLPClassifier(alpha=0.001, hidden_layer_sizes=(100, 50), max_iter=500,\n",
       "                random_state=42),\n",
       "  'accuracy': 0.9892953929539295,\n",
       "  'precision': 0.9825882352941177,\n",
       "  'recall': 0.9802816901408451,\n",
       "  'f1': 0.981433607520564,\n",
       "  'auc': 0.998367270288397,\n",
       "  'confusion_matrix': array([[5213,   37],\n",
       "         [  42, 2088]]),\n",
       "  'true_negatives': 5213,\n",
       "  'false_positives': 37,\n",
       "  'false_negatives': 42,\n",
       "  'true_positives': 2088,\n",
       "  'training_time': 10.86357593536377,\n",
       "  'y_pred': array([0, 0, 0, ..., 0, 1, 0]),\n",
       "  'y_pred_proba': array([5.37757658e-09, 3.26760535e-09, 2.32933040e-03, ...,\n",
       "         4.81750010e-03, 9.38513844e-01, 3.94600964e-12])},\n",
       " 'SVM': {'model': SVC(probability=True, random_state=42),\n",
       "  'accuracy': 0.9493224932249322,\n",
       "  'precision': 0.9106641721234799,\n",
       "  'recall': 0.9140845070422535,\n",
       "  'f1': 0.9123711340206185,\n",
       "  'auc': 0.9875272076905881,\n",
       "  'confusion_matrix': array([[5059,  191],\n",
       "         [ 183, 1947]]),\n",
       "  'true_negatives': 5059,\n",
       "  'false_positives': 191,\n",
       "  'false_negatives': 183,\n",
       "  'true_positives': 1947,\n",
       "  'training_time': 37.19989013671875,\n",
       "  'y_pred': array([0, 0, 0, ..., 0, 0, 0]),\n",
       "  'y_pred_proba': array([0.02550626, 0.03051898, 0.41649045, ..., 0.02623078, 0.40708036,\n",
       "         0.01378361])}}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calibrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, precision_recall_curve\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "# Train the final model (lightgbm choosen)\n",
    "def train_final_lightgbm_model(result_df, selected_features, random_state=42):\n",
    "    \"\"\"\n",
    "    Train and calibrate the final LightGBM model for voter turnout prediction\n",
    "    \"\"\"\n",
    "    print(\"Training final LightGBM model...\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X = result_df[selected_features].copy()\n",
    "    y = result_df['voted_last_mayoral'].copy()\n",
    "    \n",
    "    # Split data for training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training data: {X_train.shape[0]} samples\")\n",
    "    print(f\"Testing data: {X_test.shape[0]} samples\")\n",
    "    print(f\"Target distribution: {np.bincount(y_train)}\")\n",
    "    \n",
    "    # Define LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 31,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'min_data_in_leaf': 50,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    # Train LightGBM model\n",
    "    model = lgb.LGBMClassifier(**params, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Model AUC: {auc:.4f}\")\n",
    "    \n",
    "    # Calibrate probabilities\n",
    "    print(\"\\nCalibrating model probabilities...\")\n",
    "    calibrated_model = CalibratedClassifierCV(model, method='isotonic', cv='prefit')\n",
    "    calibrated_model.fit(X_test, y_test)\n",
    "    \n",
    "    # Check calibration quality\n",
    "    y_calibrated_proba = calibrated_model.predict_proba(X_test)[:, 1]\n",
    "    brier_original = brier_score_loss(y_test, y_proba)\n",
    "    brier_calibrated = brier_score_loss(y_test, y_calibrated_proba)\n",
    "    \n",
    "    print(f\"Brier score before calibration: {brier_original:.4f}\")\n",
    "    print(f\"Brier score after calibration: {brier_calibrated:.4f}\")\n",
    "    \n",
    "    # Plot calibration curve\n",
    "    plot_calibration_curve(y_test, y_proba, y_calibrated_proba)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plot_feature_importance(model, selected_features)\n",
    "    \n",
    "    # Return both the raw and calibrated models\n",
    "    return model, calibrated_model, y_test, y_proba\n",
    "\n",
    "def plot_calibration_curve(y_test, y_proba, y_calibrated_proba):\n",
    "    \"\"\"Plot calibration curves for original and calibrated models\"\"\"\n",
    "    from sklearn.calibration import calibration_curve\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Original model calibration curve\n",
    "    prob_true, prob_pred = calibration_curve(y_test, y_proba, n_bins=10)\n",
    "    plt.plot(prob_pred, prob_true, 's-', label='Original model')\n",
    "    \n",
    "    # Calibrated model calibration curve\n",
    "    prob_true_cal, prob_pred_cal = calibration_curve(y_test, y_calibrated_proba, n_bins=10)\n",
    "    plt.plot(prob_pred_cal, prob_true_cal, 's-', label='Calibrated model')\n",
    "    \n",
    "    # Perfect calibration line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Perfectly calibrated')\n",
    "    \n",
    "    plt.xlabel('Mean predicted probability')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.title('Calibration Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('calibration_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(model, features):\n",
    "    \"\"\"Plot feature importance from the model\"\"\"\n",
    "    importance = model.feature_importances_\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('LightGBM Feature Importance')\n",
    "    plt.bar(range(len(importance)), importance[indices], align='center')\n",
    "    plt.xticks(range(len(importance)), [features[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lightgbm_feature_importance.png')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SBOEID', 'RZIP5', 'ED', 'LD', 'ENROLLMENT', 'REGDATE', 'STATUS',\n",
       "       'voterhistory', 'DOB', 'parsed_history', 'has_voting_history',\n",
       "       'total_votes', 'voted_general', 'voted_primary', 'voted_local',\n",
       "       'is_consistent_voter', 'first_election_year', 'years_registered',\n",
       "       'elections_since_first', 'participation_rate',\n",
       "       'mayoral_participation_rate', 'local_participation_rate',\n",
       "       'voted_last_mayoral', 'voting_trend', 'preferred_method',\n",
       "       'prefers_early_voting', 'prefers_absentee', 'recent_method_change',\n",
       "       'recency_score', 'early_to_middle_change', 'middle_to_recent_change',\n",
       "       'participation_acceleration', 'avg_gap', 'gap_variability',\n",
       "       'longest_participation_streak', 'recent_pattern_change',\n",
       "       'participation_expansion', 'diversification_score',\n",
       "       'has_behavior_change', 'years_since_last_change', 'change_direction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final LightGBM model...\n",
      "Training data: 96600 samples\n",
      "Testing data: 24151 samples\n",
      "Target distribution: [69107 27493]\n",
      "Model accuracy: 0.9948\n",
      "Model AUC: 0.9996\n",
      "\n",
      "Calibrating model probabilities...\n",
      "Brier score before calibration: 0.0043\n",
      "Brier score after calibration: 0.0041\n"
     ]
    }
   ],
   "source": [
    "model, calibrated_model = train_final_lightgbm_model(train_df, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature anaylsis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def feature_inference(model, X, y, feature_names=None, top_n=10):\n",
    "    \"\"\"\n",
    "    Simple statistical inference for feature importance in your voter model.\n",
    "    Handles pandas DataFrame conversion issues and prevents common errors.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : your trained model (lightgbm, etc.)\n",
    "    X : pandas DataFrame of features \n",
    "    y : pandas Series of target variable\n",
    "    feature_names : list of feature names (optional, will use X.columns if None)\n",
    "    top_n : number of top features to analyze\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with statistical inference results\n",
    "    \"\"\"\n",
    "    # If feature_names not provided, use DataFrame columns\n",
    "    if feature_names is None:\n",
    "        feature_names = X.columns.tolist()\n",
    "    \n",
    "    # 1. Get model's feature importance \n",
    "    importance = model.feature_importances_ if hasattr(model, 'feature_importances_') else None\n",
    "    \n",
    "    # 2. Convert data for statsmodels (fix object dtype error)\n",
    "    print(\"Converting data for statistical analysis...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    X_copy = X.copy()\n",
    "    \n",
    "    # Ensure all columns are numeric (convert any object types)\n",
    "    for col in X_copy.columns:\n",
    "        if X_copy[col].dtype == 'object':\n",
    "            print(f\"Converting column {col} from object to numeric\")\n",
    "            X_copy[col] = pd.to_numeric(X_copy[col], errors='coerce')\n",
    "    \n",
    "    # Check for any remaining object columns\n",
    "    object_cols = X_copy.select_dtypes(include=['object']).columns.tolist()\n",
    "    if object_cols:\n",
    "        print(f\"Warning: Dropping these object columns that couldn't be converted: {object_cols}\")\n",
    "        X_copy = X_copy.drop(columns=object_cols)\n",
    "        \n",
    "    # Check for NaN values and fill them\n",
    "    if X_copy.isna().any().any():\n",
    "        print(\"Filling NaN values with 0\")\n",
    "        X_copy = X_copy.fillna(0)\n",
    "    \n",
    "    # 3. Run logistic regression for inference\n",
    "    print(\"Running logistic regression for statistical inference...\")\n",
    "    try:\n",
    "        X_sm = sm.add_constant(X_copy)\n",
    "        logit = sm.Logit(y, X_sm).fit(disp=0)\n",
    "        \n",
    "        # 4. Compile results\n",
    "        results = pd.DataFrame({\n",
    "            'Feature': ['const'] + list(X_copy.columns),\n",
    "            'Coefficient': logit.params,\n",
    "            'Std_Error': logit.bse,\n",
    "            'p_value': logit.pvalues,\n",
    "            'Odds_Ratio': np.exp(logit.params)\n",
    "        })\n",
    "        \n",
    "        # 5. Add model importance if available\n",
    "        if importance is not None:\n",
    "            # Make sure feature_names match the X_copy columns used in the regression\n",
    "            valid_features = X_copy.columns.tolist()\n",
    "            feature_indices = [i for i, f in enumerate(feature_names) if f in valid_features]\n",
    "            \n",
    "            if feature_indices:\n",
    "                valid_importance = [importance[i] for i in feature_indices]\n",
    "                imp_df = pd.DataFrame({\n",
    "                    'Feature': valid_features,\n",
    "                    'Model_Importance': valid_importance[:len(valid_features)]\n",
    "                })\n",
    "                results = results.merge(imp_df, on='Feature', how='left')\n",
    "        \n",
    "        # 6. Sort by statistical significance\n",
    "        results = results.sort_values('p_value')\n",
    "        \n",
    "        # Display top features\n",
    "        print(f\"\\nTop {top_n} Statistically Significant Features:\")\n",
    "        pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "        print(results.head(top_n)[['Feature', 'Coefficient', 'p_value', 'Odds_Ratio']])\n",
    "        \n",
    "        # Simple visualization of odds ratios (excluding intercept)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        top_features = results.iloc[1:top_n+1]  # Skip intercept\n",
    "        \n",
    "        # Plot the odds ratios\n",
    "        plt.errorbar(\n",
    "            top_features['Odds_Ratio'], \n",
    "            range(len(top_features)),\n",
    "            xerr=top_features['Std_Error'] * top_features['Odds_Ratio'],\n",
    "            fmt='o',\n",
    "            capsize=5\n",
    "        )\n",
    "        \n",
    "        plt.axvline(x=1, color='red', linestyle='--')\n",
    "        plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Odds Ratio (log scale)')\n",
    "        plt.title(f'Effect of Features on Voter Turnout (95% CI)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in regression analysis: {e}\")\n",
    "        print(\"\\nTrying alternative approach with simpler feature importance analysis...\")\n",
    "        \n",
    "        # If regression fails, at least return model's feature importance\n",
    "        if importance is not None:\n",
    "            simple_results = pd.DataFrame({\n",
    "                'Feature': feature_names,\n",
    "                'Model_Importance': importance\n",
    "            }).sort_values('Model_Importance', ascending=False)\n",
    "            \n",
    "            print(\"\\nTop features by model importance:\")\n",
    "            print(simple_results.head(top_n))\n",
    "            \n",
    "            # Simple visualization\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x='Model_Importance', y='Feature', data=simple_results.head(top_n))\n",
    "            plt.title('Feature Importance from Model')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            return simple_results\n",
    "        else:\n",
    "            print(\"Could not perform statistical inference and model has no feature_importances_\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data for statistical analysis...\n",
      "Converting column SBOEID from object to numeric\n",
      "Converting column ENROLLMENT from object to numeric\n",
      "Converting column STATUS from object to numeric\n",
      "Converting column voterhistory from object to numeric\n",
      "Converting column parsed_history from object to numeric\n",
      "Converting column preferred_method from object to numeric\n",
      "Filling NaN values with 0\n",
      "Running logistic regression for statistical inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in regression analysis: Singular matrix\n",
      "\n",
      "Trying alternative approach with simpler feature importance analysis...\n",
      "\n",
      "Top features by model importance:\n",
      "                       Feature  Model_Importance\n",
      "26     years_since_last_change               497\n",
      "15               recency_score               430\n",
      "11  mayoral_participation_rate               308\n",
      "27            change_direction               257\n",
      "17     middle_to_recent_change               203\n",
      "12    local_participation_rate               142\n",
      "16      early_to_middle_change               139\n",
      "13                voting_trend               136\n",
      "19                     avg_gap               120\n",
      "20             gap_variability               114\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Model_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>years_since_last_change</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>recency_score</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mayoral_participation_rate</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>change_direction</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>middle_to_recent_change</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>local_participation_rate</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>early_to_middle_change</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>voting_trend</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>avg_gap</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gap_variability</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>participation_rate</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>diversification_score</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>longest_participation_streak</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>years_registered</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>participation_expansion</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_votes</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>participation_acceleration</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>recent_pattern_change</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>voted_primary</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>has_behavior_change</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recent_method_change</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>elections_since_first</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>voted_local</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prefers_early_voting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prefers_absentee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is_consistent_voter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>voted_general</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>has_voting_history</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature  Model_Importance\n",
       "26       years_since_last_change               497\n",
       "15                 recency_score               430\n",
       "11    mayoral_participation_rate               308\n",
       "27              change_direction               257\n",
       "17       middle_to_recent_change               203\n",
       "12      local_participation_rate               142\n",
       "16        early_to_middle_change               139\n",
       "13                  voting_trend               136\n",
       "19                       avg_gap               120\n",
       "20               gap_variability               114\n",
       "10            participation_rate               104\n",
       "24         diversification_score               102\n",
       "21  longest_participation_streak               100\n",
       "8               years_registered                69\n",
       "23       participation_expansion                60\n",
       "1                    total_votes                59\n",
       "18    participation_acceleration                53\n",
       "22         recent_pattern_change                44\n",
       "3                  voted_primary                16\n",
       "25           has_behavior_change                14\n",
       "14          recent_method_change                14\n",
       "9          elections_since_first                10\n",
       "4                    voted_local                 8\n",
       "6           prefers_early_voting                 1\n",
       "7               prefers_absentee                 0\n",
       "5            is_consistent_voter                 0\n",
       "2                  voted_general                 0\n",
       "0             has_voting_history                 0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_df.drop(columns = ['voted_last_mayoral'])\n",
    "y = train_df['voted_last_mayoral']\n",
    "\n",
    "feature_inference(model, X, y, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Categories by Total Importance:\n",
    "\n",
    "- Temporal Pattern Features (96,177) - 35%\n",
    "- Behavior Change Features (76,846) - 28%\n",
    "- Participation Rate Features (55,467) - 20%\n",
    "- Sequence Features (24,881) - 9%\n",
    "- Diversity Features (10,822) - 4%\n",
    "- Basic Features (7,757) - 3%\n",
    "- Demographic Features (6,923) - 2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backtest final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_backtest(voter_df, model, feature_cols, test_years=[2017, 2013], mayoral_election_dates=None):\n",
    "    \"\"\"\n",
    "    Fixed backtest that properly handles all voters and features\n",
    "    \"\"\"\n",
    "    if mayoral_election_dates is None:\n",
    "        mayoral_election_dates = [\n",
    "            '20211102',\n",
    "            '20171107', \n",
    "            '20131105',\n",
    "            '20091103',\n",
    "            '20051108',\n",
    "            '20011106'\n",
    "        ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for year in test_years:\n",
    "        print(f\"\\n=== Backtesting {year} ===\")\n",
    "        \n",
    "        # 1. Create a working copy and preserve original index\n",
    "        working_df = voter_df.copy()\n",
    "        working_df['original_index'] = working_df.index\n",
    "        \n",
    "        # 2. Determine actual turnout for ALL voters\n",
    "        actual_votes = np.zeros(len(working_df))\n",
    "\n",
    "        for i, row in enumerate(working_df.itertuples(index=False)):\n",
    "            history = parse_voter_history(row.voterhistory)\n",
    "            for event in history:\n",
    "                if event['year'] == year:\n",
    "                    actual_votes[i] = 1\n",
    "                    break  # Found a match\n",
    "\n",
    "        working_df['actual_turnout'] = actual_votes\n",
    "        actual_count = sum(actual_votes)\n",
    "        print(f\"Actual voters: {actual_count}/{len(working_df)} = {actual_count/len(working_df):.1%}\")\n",
    "        \n",
    "        # 3. Filter histories to before test year\n",
    "        filtered_histories = []\n",
    "        voters_with_history = 0\n",
    "        \n",
    "        for idx, row in working_df.iterrows():\n",
    "            history = parse_voter_history(row['voterhistory'])\n",
    "            past_events = [e for e in history if e['year'] < year]\n",
    "            \n",
    "            if past_events:\n",
    "                voters_with_history += 1\n",
    "                history_str = ';'.join([\n",
    "                    f\"{e['year']} {e['election_name']}({e['vote_method']})\"\n",
    "                    for e in past_events\n",
    "                ])\n",
    "            else:\n",
    "                history_str = \"\"\n",
    "            \n",
    "            filtered_histories.append(history_str)\n",
    "        \n",
    "        working_df['voterhistory'] = filtered_histories\n",
    "        print(f\"Voters with history before {year}: {voters_with_history}\")\n",
    "        \n",
    "        # 4. Get mayoral dates before test year\n",
    "        past_mayoral_dates = [d for d in mayoral_election_dates if int(d[:4]) < year]\n",
    "        print(f\"Using mayoral dates: {[d[:4] for d in past_mayoral_dates]}\")\n",
    "        \n",
    "        # 5. Extract features - this will filter to valid histories\n",
    "        features_df, returned_feature_names = extract_clean_features_enhanced(\n",
    "            working_df,\n",
    "            parse_voter_history,\n",
    "            past_mayoral_dates\n",
    "        )\n",
    "        \n",
    "        print(f\"Features extracted for: {len(features_df)} voters\")\n",
    "        print(f\"Returned features: {len(returned_feature_names)}\")\n",
    "        \n",
    "        # 6. Create feature matrix using the features we want to use for prediction\n",
    "        if not set(feature_cols).issubset(set(features_df.columns)):\n",
    "            missing = set(feature_cols) - set(features_df.columns)\n",
    "            print(f\"WARNING: Missing features: {missing}\")\n",
    "        \n",
    "        X = features_df[feature_cols].fillna(0)\n",
    "        y_true = working_df.loc[features_df.index, 'actual_turnout']\n",
    "        \n",
    "        print(f\"Final prediction matrix shape: {X.shape}\")\n",
    "        print(f\"Eligible voters: {len(X)}\")\n",
    "        print(f\"Eligible turnout: {y_true.mean():.1%}\")\n",
    "        \n",
    "        # 7. Make predictions\n",
    "        y_proba = model.predict_proba(X)[:, 1]\n",
    "        y_pred = (y_proba >= 0.5).astype(int)\n",
    "        \n",
    "        # 8. Calculate metrics\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "        \n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, y_proba)\n",
    "        \n",
    "        \n",
    "        # 9. Segment analysis\n",
    "        segment_df = pd.DataFrame({\n",
    "            'actual': y_true,\n",
    "            'predicted_proba': y_proba\n",
    "        })\n",
    "        \n",
    "        bins = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "        segment_df['segment'] = pd.cut(y_proba, bins=bins, labels=['Low', 'Med-Low', 'Med-High', 'High'])\n",
    "        \n",
    "        segment_stats = segment_df.groupby('segment').agg({\n",
    "            'actual': ['mean', 'count'],\n",
    "            'predicted_proba': 'mean'\n",
    "        })\n",
    "        \n",
    "        # Calculate projected turnout for each segment\n",
    "        segment_stats['projected_voters'] = segment_stats[('predicted_proba', 'mean')] * segment_stats[('actual', 'count')]\n",
    "\n",
    "        # Calculate total projected turnout\n",
    "        total_voters = segment_stats[('actual', 'count')].sum()\n",
    "        total_projected_turnout = segment_stats['projected_voters'].sum()\n",
    "        projected_turnout_rate = total_projected_turnout / total_voters\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"AUC: {auc:.3f}\")\n",
    "        print(f\"Actual turnout: {y_true.mean():.1%}\")\n",
    "        print(f\"Predicted turnout: {projected_turnout_rate:.1%}\")\n",
    "        print(f\"Error: {abs(y_true.mean() - projected_turnout_rate):.1%}\")\n",
    "        \n",
    "        print(\"\\nSegment Analysis:\")\n",
    "        print(segment_stats)\n",
    "        \n",
    "        # Store results\n",
    "        results[year] = {\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc,\n",
    "            'actual_turnout': y_true.mean(),\n",
    "            'predicted_turnout': y_proba.mean(),\n",
    "            'segment_stats': segment_stats,\n",
    "            'predictions': y_proba,\n",
    "            'actuals': y_true\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Backtesting 2017 ===\n",
      "Actual voters: 34063.0/120751 = 28.2%\n",
      "Voters with history before 2017: 87418\n",
      "Using mayoral dates: ['2013', '2009']\n",
      "Extracting clean features from 120751 voter records\n",
      "Parsing voter histories...\n",
      "Kept 87418 voters with valid parsed histories\n",
      "Deriving all election dates from voter histories...\n",
      "Derived 43 election dates\n",
      "Mayoral election years: [2013, 2009]\n",
      "Local election years: [2003, 2007, 2011, 2015, 2019, 2023, 2027]\n",
      "Extracting features...\n",
      "Calculating first election information...\n",
      "Calculating normalized participation rates...\n",
      "Calculating mayoral and local participation rates...\n",
      "Setting target variable...\n",
      "Calculating voting trends...\n",
      "Feature extraction complete\n",
      "Extracting behavior change features...\n",
      "Features extracted for: 87418 voters\n",
      "Returned features: 28\n",
      "Final prediction matrix shape: (87418, 28)\n",
      "Eligible voters: 87418\n",
      "Eligible turnout: 38.2%\n",
      "\n",
      "Results:\n",
      "Accuracy: 0.694\n",
      "AUC: 0.741\n",
      "Actual turnout: 38.2%\n",
      "Predicted turnout: 9.5%\n",
      "Error: 28.7%\n",
      "\n",
      "Segment Analysis:\n",
      "            actual        predicted_proba projected_voters\n",
      "              mean  count            mean                 \n",
      "segment                                                   \n",
      "Low       0.307264  74135        0.001531       113.475128\n",
      "Med-Low   0.757058   2515        0.393005       988.406407\n",
      "Med-High  0.840408   8434        0.630972      5321.621478\n",
      "High      0.693659   2334        0.796242      1858.427938\n",
      "\n",
      "=== Backtesting 2013 ===\n",
      "Actual voters: 23776.0/120751 = 19.7%\n",
      "Voters with history before 2013: 73195\n",
      "Using mayoral dates: ['2009']\n",
      "Extracting clean features from 120751 voter records\n",
      "Parsing voter histories...\n",
      "Kept 73195 voters with valid parsed histories\n",
      "Deriving all election dates from voter histories...\n",
      "Derived 35 election dates\n",
      "Mayoral election years: [2009]\n",
      "Local election years: [2003, 2007, 2011, 2015, 2019, 2023, 2027]\n",
      "Extracting features...\n",
      "Calculating first election information...\n",
      "Calculating normalized participation rates...\n",
      "Calculating mayoral and local participation rates...\n",
      "Setting target variable...\n",
      "Calculating voting trends...\n",
      "Feature extraction complete\n",
      "Extracting behavior change features...\n",
      "Features extracted for: 73195 voters\n",
      "Returned features: 28\n",
      "Final prediction matrix shape: (73195, 28)\n",
      "Eligible voters: 73195\n",
      "Eligible turnout: 32.0%\n",
      "\n",
      "Results:\n",
      "Accuracy: 0.763\n",
      "AUC: 0.722\n",
      "Actual turnout: 32.0%\n",
      "Predicted turnout: 15.6%\n",
      "Error: 16.4%\n",
      "\n",
      "Segment Analysis:\n",
      "            actual        predicted_proba projected_voters\n",
      "              mean  count            mean                 \n",
      "segment                                                   \n",
      "Low       0.204196  55770        0.003259       181.743483\n",
      "Med-Low   0.579112   3514        0.389765      1369.634392\n",
      "Med-High  0.714117   9322        0.660435      6156.573796\n",
      "High      0.730442   4589        0.803538      3687.437595\n"
     ]
    }
   ],
   "source": [
    "# Run the fixed backtest\n",
    "results = working_backtest(\n",
    "    train_df,\n",
    "    model,\n",
    "    feature_names,  # These are the 28 features the model was trained on\n",
    "    test_years=[2017, 2013],\n",
    "    mayoral_election_dates=['20211102', '20171107', '20131105', '20091103']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, calibrated_model, features, output_dir='model'):\n",
    "    \"\"\"Save the model, calibrated model, and feature information\"\"\"\n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Save models\n",
    "    joblib.dump(model, os.path.join(output_dir, 'lightgbm_model.joblib'))\n",
    "    joblib.dump(calibrated_model, os.path.join(output_dir, 'calibrated_lightgbm_model.joblib'))\n",
    "    \n",
    "    # Save feature list\n",
    "    with open(os.path.join(output_dir, 'model_features.txt'), 'w') as f:\n",
    "        for feature in features:\n",
    "            f.write(f\"{feature}\\n\")\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'model_type': 'LightGBM',\n",
    "        'feature_count': len(features),\n",
    "        'calibration_method': 'isotonic',\n",
    "        'training_date': pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "    }\n",
    "    \n",
    "    # Write as JSON file\n",
    "    import json\n",
    "    with open(os.path.join(output_dir, 'model_metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    print(f\"Models and metadata saved to {output_dir}\")\n",
    "    return output_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and metadata saved to model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model, calibrated_model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8384d87c582b2e31d47905d5cb3d386e95c30df4c8fbac7736b5357a8c3a5d8b"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
